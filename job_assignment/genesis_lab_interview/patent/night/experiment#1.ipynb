{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/night/night_dataset.csv\")\n",
    "df_1 = df.drop('title', axis=1)\n",
    "df_1 = df_1.drop('abstract', axis=1)\n",
    "df = df_1.drop('claim', axis=1)\n",
    "\n",
    "x = df.loc[:, df.columns!='valid_patent'].astype(str)\n",
    "y = df['valid_patent'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 773, 1: 92})\n",
      "Resampled dataset shape Counter({0: 773, 1: 773})\n",
      "Y test dataset shpae Counter({0: 336, 1: 35})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape {}'.format(Counter(y_train)))\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res , y_res = sm.fit_sample(x_train, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print('Y test dataset shpae {}'.format(Counter(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85       336\n",
      "          1       0.14      0.31      0.19        35\n",
      "\n",
      "avg / total       0.84      0.75      0.79       371\n",
      "\n",
      "This is accuracy score: 0.7493261455525606 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(fit_intercept=False)\n",
    "logreg.fit(x_res, y_res)\n",
    "\n",
    "result = logreg.predict(x_test)\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, result))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, result),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.24      0.38       336\n",
      "          1       0.11      0.89      0.19        35\n",
      "\n",
      "avg / total       0.87      0.30      0.36       371\n",
      "\n",
      "This is accuracy score: 0.2991913746630728 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob = logreg.predict_proba(x_test)\n",
    "\n",
    "y_pred = np.zeros(len(x_test))\n",
    "y_pred[prob[:,1] > 0.35] = 1\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, y_pred))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.76      0.82       336\n",
      "          1       0.05      0.11      0.07        35\n",
      "\n",
      "avg / total       0.81      0.70      0.75       371\n",
      "\n",
      "This is accuracy score: 0.7008086253369272 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "svm = svm.LinearSVC()\n",
    "svm.fit(x_res, y_res)\n",
    "\n",
    "result = svm.predict(x_test)\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, result))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, result),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85       336\n",
      "          1       0.14      0.31      0.19        35\n",
      "\n",
      "avg / total       0.84      0.75      0.79       371\n",
      "\n",
      "This is accuracy score: 0.7493261455525606 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "svc = CalibratedClassifierCV(base_estimator=LinearSVC(penalty='l2', dual=False), cv=5)\n",
    "svc.fit(x_res, y_res)\n",
    "\n",
    "\n",
    "result = svc.predict(x_test)\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, result))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, result),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       336\n",
      "          1       0.00      0.00      0.00        35\n",
      "\n",
      "avg / total       0.82      0.91      0.86       371\n",
      "\n",
      "This is accuracy score: 0.9056603773584906 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yehoon/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prob = svc.predict_proba(x_test)\n",
    "\n",
    "y_pred = np.zeros(len(x_test))\n",
    "y_pred[prob[:,-1] > 0.75] = 1\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, y_pred))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       565\n",
      "          1       0.36      0.57      0.44         7\n",
      "\n",
      "avg / total       0.99      0.98      0.98       572\n",
      "\n",
      "This is accuracy score: 0.9825174825174825 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf=5)\n",
    "dt.fit(x_res, y_res)\n",
    "\n",
    "result = dt.predict(x_test)\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, result))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, result),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       565\n",
      "          1       0.44      0.57      0.50         7\n",
      "\n",
      "avg / total       0.99      0.99      0.99       572\n",
      "\n",
      "This is accuracy score: 0.986013986013986 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob = dt.predict_proba(x_test)\n",
    "\n",
    "y_pred = np.zeros(len(x_test))\n",
    "y_pred[prob[:,-1] > 0.75] = 1\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, y_pred))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       565\n",
      "          1       0.75      0.86      0.80         7\n",
      "\n",
      "avg / total       1.00      0.99      0.99       572\n",
      "\n",
      "This is accuracy score: 0.9947552447552448 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=5)\n",
    "rf.fit(x_res, y_res)\n",
    "\n",
    "result = rf.predict(x_test)\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, result))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, result),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00       565\n",
      "          1       1.00      0.43      0.60         7\n",
      "\n",
      "avg / total       0.99      0.99      0.99       572\n",
      "\n",
      "This is accuracy score: 0.993006993006993 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prob = rf.predict_proba(x_test)\n",
    "\n",
    "y_pred = np.zeros(len(x_test))\n",
    "y_pred[prob[:,-1] > 0.8] = 1\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, y_pred))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This classification report of using threshold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.89      0.94       565\n",
      "          1       0.02      0.14      0.03         7\n",
      "\n",
      "avg / total       0.98      0.88      0.92       572\n",
      "\n",
      "This is accuracy score: 0.8793706293706294 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(learning_rate_init=0.01, activation='relu', solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100, ), random_state=1)\n",
    "mlp.fit(x_res, y_res)\n",
    "\n",
    "result = mlp.predict(x_test)\n",
    "\n",
    "print(\"This classification report of using threshold: \\n\",classification_report(y_test, result))\n",
    "print (\"This is accuracy score:\",metrics.accuracy_score(y_test, result),\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
