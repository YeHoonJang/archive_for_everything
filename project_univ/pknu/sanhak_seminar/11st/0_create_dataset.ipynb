{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463a94f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5061be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /home/yehoon/anaconda3/envs/torch/lib/python3.7/site-packages (from h5py) (1.21.6)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "306f4683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba9701",
   "metadata": {},
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "- 참고 : https://github.com/lime-robot/categories-prediction/blob/1cdaf3797285bfc8b9dc1118adc6a5230a394b97/code/preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa329616",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"./input/raw_data\" # 카카오에서 다운로드 받은 데이터의 디렉터리\n",
    "\n",
    "train_file_list = [\n",
    "    \"train.chunk.01\",\n",
    "    \"train.chunk.02\",\n",
    "    \"train.chunk.03\",\n",
    "    \"train.chunk.04\",\n",
    "    \"train.chunk.05\",\n",
    "    \"train.chunk.06\",\n",
    "    \"train.chunk.07\",\n",
    "    \"train.chunk.08\",\n",
    "    \"train.chunk.09\"\n",
    "]\n",
    "\n",
    "dev_file_list = [\n",
    "    \"dev.chunk.01\"    \n",
    "]\n",
    "\n",
    "test_file_list = [\n",
    "    \"test.chunk.01\",\n",
    "    \"test.chunk.02\", \n",
    "]\n",
    "\n",
    "train_path_list = [os.path.join(RAW_DATA_DIR, fn) for fn in train_file_list]\n",
    "dev_path_list = [os.path.join(RAW_DATA_DIR, fn) for fn in dev_file_list]\n",
    "test_path_list = [os.path.join(RAW_DATA_DIR, fn) for fn in test_file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a5a8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_list의 파일에서 col 변수에 해당하는 컬럼 값들을 가져온다.\n",
    "def get_column_data(path_list, div, col):\n",
    "    col_data = []\n",
    "    for path in path_list:\n",
    "        h = h5py.File(path, 'r')\n",
    "        col_data.append(h[div][col][:])\n",
    "        h.close()\n",
    "    return np.concatenate(col_data)\n",
    "\n",
    "\n",
    "# path_list의 파일에서 학습에 필요한 컬럼들을 DataFrame 포맷으로 반환한다.\n",
    "def get_dataframe(path_list, div):\n",
    "    pids = get_column_data(path_list, div, col='pid')\n",
    "    products = get_column_data(path_list, div, col='product')\n",
    "    brands = get_column_data(path_list, div, col='brand')\n",
    "    makers = get_column_data(path_list, div, col='maker')\n",
    "    models = get_column_data(path_list, div, col='model') \n",
    "    prices = get_column_data(path_list, div, col='price')\n",
    "    updttms = get_column_data(path_list, div, col='updttm')\n",
    "    bcates = get_column_data(path_list, div, col='bcateid')\n",
    "    mcates = get_column_data(path_list, div, col='mcateid')\n",
    "    scates = get_column_data(path_list, div, col='scateid')\n",
    "    dcates = get_column_data(path_list, div, col='dcateid')\n",
    "    \n",
    "    df = pd.DataFrame({'pid': pids, \n",
    "                       'product': products, \n",
    "                       'brand': brands, \n",
    "                       'maker': makers, \n",
    "                       'model': models, \n",
    "                       'price': prices, \n",
    "                       'updttm': updttms, \n",
    "                       'bcateid': bcates, \n",
    "                       'mcateid': mcates, \n",
    "                       'scateid': scates, \n",
    "                       'dcateid': dcates})\n",
    "    \n",
    "    # 바이트 열로 인코딩 상품제목과 상품ID를 유니코드 변환한다.\n",
    "    df['pid'] = df['pid'].map(lambda x: x.decode('utf-8'))\n",
    "    df['product'] = df['product'].map(lambda x: x.decode('utf-8'))\n",
    "    df['brand'] = df['brand'].map(lambda x: x.decode('utf-8'))\n",
    "    df['maker'] = df['maker'].map(lambda x: x.decode('utf-8'))\n",
    "    df['model'] = df['model'].map(lambda x: x.decode('utf-8'))\n",
    "    df['updttm'] = df['updttm'].map(lambda x: x.decode('utf-8'))     \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bceb2a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = './input/raw_data/train.chunk.01', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_205282/102805816.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#8134818\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_205282/1365514933.py\u001b[0m in \u001b[0;36mget_dataframe\u001b[0;34m(path_list, div)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# path_list의 파일에서 학습에 필요한 컬럼들을 DataFrame 포맷으로 반환한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_column_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_column_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'product'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbrands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_column_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'brand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_205282/1365514933.py\u001b[0m in \u001b[0;36mget_column_data\u001b[0;34m(path_list, div, col)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcol_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mcol_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = './input/raw_data/train.chunk.01', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "df = get_dataframe(train_path_list, 'train')\n",
    "\n",
    "df.head() #8134818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc3a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 이름과 ID의 매핑 정보를 불러온다.\n",
    "cate_json = json.load(open(os.path.join(RAW_DATA_DIR, 'cate1.json')))\n",
    "\n",
    "# (이름, ID) 순서를 (ID, 이름)으로 바꾼 후 dictionary로 만든다.\n",
    "bid2nm = dict([(cid, name) for name, cid in cate_json['b'].items()]) # 대 \n",
    "mid2nm = dict([(cid, name) for name, cid in cate_json['m'].items()]) # 중\n",
    "sid2nm = dict([(cid, name) for name, cid in cate_json['s'].items()]) # 소\n",
    "did2nm = dict([(cid, name) for name, cid in cate_json['d'].items()]) # 세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bcatenm'] = df['bcateid'].map(bid2nm)\n",
    "df['mcatenm'] = df['mcateid'].map(mid2nm)\n",
    "df['scatenm'] = df['scateid'].map(sid2nm)\n",
    "df['dcatenm'] = df['dcateid'].map(did2nm)\n",
    "\n",
    "df['updttm'] = pd.to_datetime(df['updttm'], format='%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['bcateid', 'mcateid', 'scateid', 'dcateid'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee535a87",
   "metadata": {},
   "source": [
    "# 디지털 / 가전 관련 카테고리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디지털 / 가전\n",
    "\n",
    "bctgr_list = ['계절가전/에어컨/온열기기',\n",
    "              '내비/블랙박스/하이패스',\n",
    "              '노트북/태블릿PC',\n",
    "              '데스크탑/모니터/PC부품',\n",
    "              '디카/캠코더/주변기기',\n",
    "              '생활가전/세탁기/청소기',\n",
    "              '영상가전/TV/홈시어터',\n",
    "              '음향가전/스피커/전자사전',\n",
    "              '주방가전/냉장고/전기밥솥',\n",
    "              '프린터/PC주변/사무기기']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168774f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df = df[df['bcatenm'].isin(bctgr_list)].copy()\n",
    "digital_df = digital_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9626a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df.to_pickle('./input/digital_prd_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85391fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05a1f1c",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e33d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df = pd.read_pickle('./input/digital_prd_list.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58739ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 괄호 제거\n",
    "def remove_brackets(text):\n",
    "    text = re.sub('\\[([^\\[^\\]]+)\\]', lambda m: f\" {m.group(1)} \", text)\n",
    "    text = re.sub('\\(([^\\(^\\)]+)\\)', lambda m: f\" {m.group(1)} \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def add_space(text):\n",
    "    return re.sub('([가-힣]+)', r' \\1 ', text).strip()\n",
    "\n",
    "\n",
    "# 참고 : 정규식표현(패스워드) : https://heeya7.tistory.com/37\n",
    "prd_code_re = re.compile(\n",
    "    \"(^(?=.*[a-z])(?=.*\\d)[a-z\\d\\-\\_\\.]{3,}$)\" + \"|\" + \\\n",
    "    \"(^(?=.*[a-z])(?=.*[\\-\\_\\.])[a-z\\d\\-\\_\\.]{3,}$)\" + \"|\" + \\\n",
    "    \"(^(?=.*\\d)(?=.*[\\-\\_\\.])[a-z\\d\\-\\_\\.]{3,}$)\"\n",
    ")\n",
    "\n",
    "def get_prd_code(string):\n",
    "    matched_prd_code = prd_code_re.match(string)\n",
    "    if matched_prd_code:\n",
    "        return matched_prd_code.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42347543",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df['product'] = digital_df['product'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 괄호 제거\n",
    "digital_df.loc[:, 'product'] = digital_df.loc[:, 'product'].map(remove_brackets)\n",
    "# /, + 제거\n",
    "digital_df.loc[:, 'product'] = digital_df.loc[:, 'product'].str.replace('/|\\+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글단어 앞뒤로 공백 추가\n",
    "digital_df.loc[:, 'product'] = digital_df.loc[:, 'product'].map(add_space)\n",
    "# '      ' -> ' '\n",
    "digital_df.loc[:, 'product'] = digital_df.loc[:, 'product'].str.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771935e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df['product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee59d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델명 후보군 추출\n",
    "digital_df.loc[:, 'product_terms'] = digital_df.loc[:, 'product'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df.loc[:, 'product_terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41925c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df.loc[:, 'product_terms'] = digital_df.loc[:, 'product_terms'].map(lambda x: list(filter(get_prd_code, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df[['product', 'product_terms']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62811db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model column 에도 동일 로직 적용\n",
    "digital_df['model'] = digital_df['model'].str.lower()\n",
    "\n",
    "digital_df.loc[:, 'model'] = digital_df.loc[:, 'model'].map(remove_brackets)\n",
    "digital_df.loc[:, 'model'] = digital_df.loc[:, 'model'].str.replace('/|\\+', ' ', regex=True)\n",
    "\n",
    "digital_df.loc[:, 'model'] = digital_df.loc[:, 'model'].map(add_space)\n",
    "digital_df.loc[:, 'model'] = digital_df.loc[:, 'model'].str.replace('\\s+', ' ', regex=True)\n",
    "\n",
    "digital_df.loc[:, 'model_terms'] = digital_df.loc[:, 'model'].str.split()\n",
    "digital_df.loc[:, 'model_terms'] = digital_df.loc[:, 'model_terms'].map(lambda x: list(filter(get_prd_code, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620738f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df[['product', 'product_terms', 'model_terms', 'model']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-term 과 일치하는 product-term 은 True, 아니면 False\n",
    "\n",
    "digital_df.loc[:, 'dataset'] = digital_df[['product_terms', 'model_terms']].apply(\n",
    "    lambda x: {term: term in x[1] for term in x[0]}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2867c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df[['product', 'product_terms', 'model_terms', 'dataset']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d246705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_dict = defaultdict(list)\n",
    "\n",
    "for term_dict in digital_df['dataset'].values:\n",
    "    for term, v in term_dict.items():\n",
    "        model_name_dict[term].append(v)\n",
    "        \n",
    "for term in list(chain(*digital_df['model_terms'])):\n",
    "    model_name_dict[term].append(True)\n",
    "    model_name_dict[term].append(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38698d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [(name, (sum(count) / len(count)) >= 0.5) for name, count in model_name_dict.items() if len(count) >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f3a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sum([labels for term, labels in datasets]), \"/\" , len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ea3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_df['brand_norm'] = digital_df['brand'].str.lower().str.replace(' ', '')\n",
    "digital_df['brand_norm'] = digital_df['brand_norm'].str.strip().str.replace('\\(|\\)', '', regex=True)\n",
    "\n",
    "digital_df['product_norm'] = digital_df['product'].str.lower().str.replace(' ', '')\n",
    "digital_df['product_norm'] = digital_df['product_norm'].str.strip().str.replace('\\(|\\)', '', regex=True)\n",
    "\n",
    "digital_df['maker_norm'] = digital_df['maker'].str.lower().str.replace(' ', '')\n",
    "digital_df['maker_norm'] = digital_df['maker_norm'].str.strip().str.replace('\\(|\\)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5efa883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_df = digital_df.loc[\n",
    "    digital_df['dataset'] != {}, \n",
    "    ['product', 'dataset', 'brand', 'maker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352026ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_df['dataset'] = model_name_df['dataset'].map(dict.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78498fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85327cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict item to pandas row\n",
    "model_name_df = model_name_df.explode('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88915bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_df['model_name'] = model_name_df['dataset'].str[0]\n",
    "model_name_df['label'] = model_name_df['dataset'].str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f034a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_df.to_pickle('model_name_dataset.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "237px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
